# Deep-Eye: Automatic Image Captioning Application for visually impaired people (with Deep Learning)
## Introduction
The “Deep Eye” project is an innovative and cutting-edge system that leverages deep
learning techniques to provide image captioning capabilities. It aims to bridge the gap
between computer vision and natural language processing by automatically generating
descriptive captions for images. This project holds significant potential in various domains,
including assistive technology, content indexing, and enhancing user experiences with
image-based applications.

## Working of the Project
### Image Capture:
The “Deep Eye” application operates in real time and automatically captures images using
the smartphone's camera. This feature allows visually impaired users to obtain images of
their surroundings effortlessly. The application uses the captured image as input for the
subsequent image captioning process.
### Image Recognition:
“Deep Eye” employs deep learning models, including Convolutional Neural Networks
(CNNs), to recognize objects, scenes, and other visual elements within the captured image.
The trained CNN model analyzes the image and extracts features that represent different
visual components.
### Caption Generation:
To generate descriptive captions, Model utilizes a Long Short-Term Memory (LSTM)
network, which is a type of recurrent neural network (RNN). The LSTM model takes the
extracted image features as input and generates contextually relevant captions that describe
the visual content in the image. The captions are designed to be informative and meaningful
to visually impaired users.
### Audio Output:
The generated captions are converted into audio output, allowing visually impaired
individuals to hear the descriptions of the images. Model utilizes text-to-speech synthesis
technology to provide natural and intelligible audio descriptions. The application delivers
the audio output through the smartphone's speaker or connected audio devices, ensuring
seamless accessibility for visually impaired users.
